

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>src.MCMC &mdash; Bayesian MCMC Framework 1.0 documentation</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=80d5e7a1" />
      <link rel="stylesheet" type="text/css" href="../../_static/css/theme.css?v=e59714d7" />

  
      <script src="../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../_static/documentation_options.js?v=f2a433a1"></script>
      <script src="../../_static/doctools.js?v=9a2dae69"></script>
      <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html" class="icon icon-home">
            Bayesian MCMC Framework
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Python API:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../modules.html">Bayesian-Markov-chain-Monte-Carlo</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">Bayesian MCMC Framework</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../index.html">Module code</a></li>
      <li class="breadcrumb-item active">src.MCMC</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for src.MCMC</h1><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">setup_path</span>
<span class="kn">from</span> <span class="nn">src.imports</span> <span class="kn">import</span> <span class="o">*</span>


<div class="viewcode-block" id="MCMC">
<a class="viewcode-back" href="../../src.html#src.MCMC.MCMC">[docs]</a>
<span class="k">class</span> <span class="nc">MCMC</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Adaptive Metropolis-Hastings Markov Chain Monte Carlo (MCMC) sampler.</span>
<span class="sd">    </span>
<span class="sd">    This class implements an adaptive MCMC algorithm for Bayesian parameter estimation.</span>
<span class="sd">    It uses the Metropolis-Hastings algorithm with adaptive covariance matrix updates</span>
<span class="sd">    to improve sampling efficiency. The algorithm is particularly suited for sampling</span>
<span class="sd">    from posterior distributions in inverse problems where direct sampling is difficult.</span>
<span class="sd">    </span>
<span class="sd">    The adaptive feature automatically adjusts the proposal covariance matrix during</span>
<span class="sd">    sampling to achieve better acceptance rates and mixing. The algorithm also</span>
<span class="sd">    incorporates hierarchical Bayesian modeling by updating the noise variance</span>
<span class="sd">    (standard deviation) at each step.</span>
<span class="sd">    </span>
<span class="sd">    Attributes:</span>
<span class="sd">        model: The forward model used for evaluation</span>
<span class="sd">        qstart (float): Initial parameter value for sampling</span>
<span class="sd">        qpriors (dict): Prior parameter bounds and information</span>
<span class="sd">        nsamples (int): Total number of MCMC samples to generate</span>
<span class="sd">        nburn (int): Number of burn-in samples to discard</span>
<span class="sd">        verbose (bool): Whether to print diagnostic information</span>
<span class="sd">        adapt_interval (int): Frequency of covariance matrix adaptation</span>
<span class="sd">        data (np.ndarray): Observed data for comparison</span>
<span class="sd">        lstm_model (dict): Optional LSTM model configuration</span>
<span class="sd">        n0 (float): Prior shape parameter for noise variance</span>
<span class="sd">        qstart_limits (np.ndarray): Parameter bounds for acceptance</span>
<span class="sd">        dc_true (float): True parameter value (for comparison/validation)</span>
<span class="sd">        std2 (list): Evolution of noise variance estimates</span>
<span class="sd">        Vstart (np.ndarray): Initial covariance matrix</span>
<span class="sd">    </span>
<span class="sd">    Example:</span>
<span class="sd">        &gt;&gt;&gt; # Setup model and data</span>
<span class="sd">        &gt;&gt;&gt; model = MyForwardModel()</span>
<span class="sd">        &gt;&gt;&gt; data = np.array([1.2, 1.5, 1.8])</span>
<span class="sd">        &gt;&gt;&gt; priors = {1: 0.5, 2: 2.0}  # lower_bound, upper_bound</span>
<span class="sd">        &gt;&gt;&gt; </span>
<span class="sd">        &gt;&gt;&gt; # Initialize MCMC sampler</span>
<span class="sd">        &gt;&gt;&gt; mcmc = MCMC(model=model, data=data, dc_true=1.0, </span>
<span class="sd">        ...             qpriors=priors, qstart=1.2, nsamples=1000)</span>
<span class="sd">        &gt;&gt;&gt; </span>
<span class="sd">        &gt;&gt;&gt; # Run sampling</span>
<span class="sd">        &gt;&gt;&gt; samples = mcmc.sample(MAKE_ANIMATIONS=False)</span>
<span class="sd">        &gt;&gt;&gt; print(f&quot;Posterior mean: {np.mean(samples):.3f}&quot;)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> 
        <span class="n">model</span><span class="p">,</span> 
        <span class="n">data</span><span class="p">,</span>
        <span class="n">dc_true</span><span class="p">,</span> 
        <span class="n">qpriors</span><span class="p">,</span> 
        <span class="n">qstart</span><span class="p">,</span> 
        <span class="n">nsamples</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> 
        <span class="n">lstm_model</span><span class="o">=</span><span class="p">{},</span> 
        <span class="n">adapt_interval</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> 
        <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initialize the MCMC sampler with model, data, and sampling parameters.</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            model: Forward model object that can evaluate predictions given parameters.</span>
<span class="sd">                  Must have a &#39;Dc&#39; attribute that can be set and an &#39;evaluate()&#39; method.</span>
<span class="sd">            data (np.ndarray): Observed data vector for likelihood computation.</span>
<span class="sd">                             Should be 1D array of observations.</span>
<span class="sd">            dc_true (float): True parameter value used for validation and animation labels.</span>
<span class="sd">            qpriors (dict): Dictionary containing prior bounds. Expected format:</span>
<span class="sd">                          {1: lower_bound, 2: upper_bound} for uniform prior.</span>
<span class="sd">            qstart (float): Initial parameter value to start the MCMC chain.</span>
<span class="sd">                          Should be within the prior bounds.</span>
<span class="sd">            nsamples (int, optional): Total number of MCMC samples to generate. </span>
<span class="sd">                                    Defaults to 100.</span>
<span class="sd">            lstm_model (dict, optional): Configuration for LSTM-based reduced order model.</span>
<span class="sd">                                       If provided, uses ROM evaluation. Defaults to {}.</span>
<span class="sd">            adapt_interval (int, optional): Number of samples between covariance matrix</span>
<span class="sd">                                          adaptations. Defaults to 10.</span>
<span class="sd">            verbose (bool, optional): Whether to print diagnostic information during</span>
<span class="sd">                                    sampling. Defaults to True.</span>
<span class="sd">        </span>
<span class="sd">        Note:</span>
<span class="sd">            - Burn-in period is automatically set to half of nsamples</span>
<span class="sd">            - The noise variance prior uses n0=0.01 as the shape parameter</span>
<span class="sd">            - Parameter bounds are derived from qpriors for proposal acceptance</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span>          <span class="o">=</span> <span class="n">model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">qstart</span>         <span class="o">=</span> <span class="n">qstart</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">qpriors</span>        <span class="o">=</span> <span class="n">qpriors</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">nsamples</span>       <span class="o">=</span> <span class="n">nsamples</span> <span class="c1"># number of samples to take during MCMC algorithm</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">nburn</span>          <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">nsamples</span><span class="o">/</span><span class="mi">2</span><span class="p">)</span> <span class="c1"># number of samples to discard during burn-in period</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span>        <span class="o">=</span> <span class="n">verbose</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">adapt_interval</span> <span class="o">=</span> <span class="n">adapt_interval</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">data</span>           <span class="o">=</span> <span class="n">data</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lstm_model</span>     <span class="o">=</span> <span class="n">lstm_model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n0</span>             <span class="o">=</span> <span class="mf">0.01</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">qstart_limits</span>  <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="bp">self</span><span class="o">.</span><span class="n">qpriors</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">qpriors</span><span class="p">[</span><span class="mi">2</span><span class="p">]]])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dc_true</span>        <span class="o">=</span> <span class="n">dc_true</span>

        <span class="k">return</span>

<div class="viewcode-block" id="MCMC.evaluate_model">
<a class="viewcode-back" href="../../src.html#src.MCMC.MCMC.evaluate_model">[docs]</a>
    <span class="k">def</span> <span class="nf">evaluate_model</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Evaluate the forward model for current parameter values.</span>
<span class="sd">        </span>
<span class="sd">        This method provides a unified interface for model evaluation, automatically</span>
<span class="sd">        selecting between full model evaluation and reduced-order model (ROM) evaluation</span>
<span class="sd">        based on whether an LSTM model is provided.</span>
<span class="sd">        </span>
<span class="sd">        Returns:</span>
<span class="sd">            np.ndarray: Model predictions/outputs for the current parameter values.</span>
<span class="sd">                       The specific format depends on the model implementation.</span>
<span class="sd">        </span>
<span class="sd">        Note:</span>
<span class="sd">            - If lstm_model is provided and non-empty, uses ROM evaluation</span>
<span class="sd">            - Otherwise uses standard model evaluation</span>
<span class="sd">            - The model&#39;s &#39;Dc&#39; attribute should be set before calling this method</span>
<span class="sd">        </span>
<span class="sd">        Example:</span>
<span class="sd">            &gt;&gt;&gt; self.model.Dc = 1.5</span>
<span class="sd">            &gt;&gt;&gt; predictions = self.evaluate_model()</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">lstm_model</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">reduced_order_model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lstm_model</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">()[</span><span class="mi">1</span><span class="p">]</span></div>

            
<div class="viewcode-block" id="MCMC.update_standard_deviation">
<a class="viewcode-back" href="../../src.html#src.MCMC.MCMC.update_standard_deviation">[docs]</a>
    <span class="k">def</span> <span class="nf">update_standard_deviation</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">SSqprev</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Update the noise variance estimate using Bayesian inference.</span>
<span class="sd">        </span>
<span class="sd">        This method implements a hierarchical Bayesian approach where the noise</span>
<span class="sd">        variance (standard deviation squared) is treated as an unknown parameter</span>
<span class="sd">        with an inverse-gamma prior. The posterior is also inverse-gamma distributed,</span>
<span class="sd">        allowing for analytical updates.</span>
<span class="sd">        </span>
<span class="sd">        The update follows the inverse-gamma conjugate prior framework:</span>
<span class="sd">        - Prior: σ² ~ InverseGamma(n0/2, n0*σ0²/2)</span>
<span class="sd">        - Posterior: σ² ~ InverseGamma((n0+n)/2, (n0*σ0² + SSE)/2)</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            SSqprev (float): Sum of squared errors for the current parameter values.</span>
<span class="sd">                           Used to update the scale parameter of the inverse-gamma</span>
<span class="sd">                           distribution.</span>
<span class="sd">        </span>
<span class="sd">        Note:</span>
<span class="sd">            - Updates self.std2 list with new variance sample</span>
<span class="sd">            - Uses the previous variance estimate (self.std2[-1]) in the update</span>
<span class="sd">            - The variance sample is drawn from the posterior distribution</span>
<span class="sd">            - Accept/reject criterion depends on this updated standard deviation</span>
<span class="sd">        </span>
<span class="sd">        Mathematical Details:</span>
<span class="sd">            - Shape parameter: a = (n0 + len(data)) / 2</span>
<span class="sd">            - Scale parameter: b = (n0 * previous_variance + SSE) / 2  </span>
<span class="sd">            - New variance: σ² ~ InverseGamma(a, b)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">aval</span> <span class="o">=</span> <span class="mf">0.5</span><span class="o">*</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n0</span><span class="o">+</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">))</span>
        <span class="n">bval</span> <span class="o">=</span> <span class="mf">0.5</span><span class="o">*</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n0</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">std2</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">+</span><span class="n">SSqprev</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">std2</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="n">gamma</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">aval</span><span class="p">,</span><span class="n">scale</span><span class="o">=</span><span class="mi">1</span><span class="o">/</span><span class="n">bval</span><span class="p">,</span><span class="n">size</span><span class="o">=</span><span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">])</span></div>


<div class="viewcode-block" id="MCMC.update_covariance_matrix">
<a class="viewcode-back" href="../../src.html#src.MCMC.MCMC.update_covariance_matrix">[docs]</a>
    <span class="k">def</span> <span class="nf">update_covariance_matrix</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">qparams</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Update the proposal covariance matrix for adaptive MCMC.</span>
<span class="sd">        </span>
<span class="sd">        This method implements the adaptive Metropolis algorithm by updating the</span>
<span class="sd">        proposal covariance matrix based on the sample covariance of recent parameter</span>
<span class="sd">        samples. This adaptation improves the efficiency of the MCMC sampler by</span>
<span class="sd">        learning the appropriate scale and orientation for proposals.</span>
<span class="sd">        </span>
<span class="sd">        The method follows the optimal scaling theory for MCMC, using:</span>
<span class="sd">        - Scaling factor: (2.38)²/d where d is the dimension</span>
<span class="sd">        - Sample covariance from the last &#39;adapt_interval&#39; samples</span>
<span class="sd">        - Cholesky decomposition for numerical stability in proposal generation</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            qparams (np.ndarray): Array of parameter samples with shape (n_params, n_samples).</span>
<span class="sd">                                The method uses only the last &#39;adapt_interval&#39; samples</span>
<span class="sd">                                for covariance estimation.</span>
<span class="sd">        </span>
<span class="sd">        Returns:</span>
<span class="sd">            np.ndarray: Lower triangular Cholesky factor of the updated covariance matrix.</span>
<span class="sd">                       Used for generating correlated proposals via matrix multiplication.</span>
<span class="sd">        </span>
<span class="sd">        Raises:</span>
<span class="sd">            LinAlgError: If the sample covariance matrix is not positive definite.</span>
<span class="sd">                        This can happen with insufficient samples or highly correlated chains.</span>
<span class="sd">        </span>
<span class="sd">        Note:</span>
<span class="sd">            - The 2.38² scaling ensures optimal acceptance rate (~23.4%) for Gaussian targets</span>
<span class="sd">            - For 1D problems, the covariance is reshaped to maintain matrix structure</span>
<span class="sd">            - The Cholesky factor is returned for efficient proposal generation</span>
<span class="sd">            - Adaptation should only occur after sufficient samples for stable covariance estimation</span>
<span class="sd">        </span>
<span class="sd">        Mathematical Details:</span>
<span class="sd">            - Optimal covariance: C_opt = (2.38²/d) * Σ_sample</span>
<span class="sd">            - Where Σ_sample is the empirical covariance of recent samples</span>
<span class="sd">            - Cholesky decomposition: C_opt = L * L^T</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">Vnew</span> <span class="o">=</span> <span class="mf">2.38</span><span class="o">**</span><span class="mi">2</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">qpriors</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">cov</span><span class="p">(</span><span class="n">qparams</span><span class="p">[:,</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">adapt_interval</span><span class="p">:])</span>
        <span class="k">if</span> <span class="n">qparams</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">==</span><span class="mi">1</span><span class="p">:</span>
            <span class="n">Vnew</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">Vnew</span><span class="p">,(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
        <span class="n">Vnew</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">cholesky</span><span class="p">(</span><span class="n">Vnew</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">Vnew</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span></div>


<div class="viewcode-block" id="MCMC.compute_initial_covariance">
<a class="viewcode-back" href="../../src.html#src.MCMC.MCMC.compute_initial_covariance">[docs]</a>
    <span class="k">def</span> <span class="nf">compute_initial_covariance</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute the initial proposal covariance matrix using finite differences.</span>
<span class="sd">        </span>
<span class="sd">        This method estimates the initial covariance matrix for MCMC proposals by</span>
<span class="sd">        computing a finite difference approximation of the Hessian matrix. The approach</span>
<span class="sd">        perturbs the initial parameter guess and evaluates how the model response changes,</span>
<span class="sd">        providing information about the local curvature of the posterior distribution.</span>
<span class="sd">        </span>
<span class="sd">        The method performs the following steps:</span>
<span class="sd">        1. Evaluates the model at the initial parameter guess</span>
<span class="sd">        2. Perturbs the parameter by a small amount (1e-6 relative)</span>
<span class="sd">        3. Re-evaluates the model with the perturbed parameter</span>
<span class="sd">        4. Computes finite difference approximation of the gradient</span>
<span class="sd">        5. Estimates the Hessian and its inverse for the covariance matrix</span>
<span class="sd">        6. Scales by the noise variance estimate</span>
<span class="sd">        </span>
<span class="sd">        Updates:</span>
<span class="sd">            self.std2 (list): Initializes with the noise variance estimate from residuals</span>
<span class="sd">            self.Vstart (np.ndarray): Initial covariance matrix for proposals</span>
<span class="sd">        </span>
<span class="sd">        Mathematical Details:</span>
<span class="sd">            - Finite difference gradient: g ≈ (f(x+δ) - f(x)) / δ</span>
<span class="sd">            - Hessian approximation: H ≈ g^T * g (Gauss-Newton approximation)</span>
<span class="sd">            - Initial covariance: V₀ = σ² * H⁻¹</span>
<span class="sd">            - Noise variance: σ² = SSE / (n - p) where n=data points, p=parameters</span>
<span class="sd">        </span>
<span class="sd">        Note:</span>
<span class="sd">            - Uses a relative perturbation of 1e-6 for finite differences</span>
<span class="sd">            - The noise variance is estimated from the initial residuals</span>
<span class="sd">            - This provides a reasonable starting point for the adaptive algorithm</span>
<span class="sd">            - The method assumes the posterior is approximately Gaussian locally</span>
<span class="sd">        </span>
<span class="sd">        Example:</span>
<span class="sd">            &gt;&gt;&gt; mcmc.compute_initial_covariance()</span>
<span class="sd">            &gt;&gt;&gt; print(f&quot;Initial noise variance: {mcmc.std2[0]:.6f}&quot;)</span>
<span class="sd">            &gt;&gt;&gt; print(f&quot;Initial covariance shape: {mcmc.Vstart.shape}&quot;)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Initial Guess</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">Dc</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">qstart</span>

        <span class="c1"># Evaluate the model on the initial guess                 </span>
        <span class="n">acc_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">evaluate_model</span><span class="p">()</span>

        <span class="c1"># Perturb the dc value</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">Dc</span> <span class="o">*=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="mf">1e-6</span><span class="p">)</span>

        <span class="c1"># Evaluate the model with the perturbed dc value</span>
        <span class="n">acc_dq_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">evaluate_model</span><span class="p">()</span>

        <span class="c1"># Extract the values and reshape them to a 1D array</span>
        <span class="n">acc</span> <span class="o">=</span> <span class="n">acc_</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">acc_dq</span> <span class="o">=</span> <span class="n">acc_dq_</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># Compute the variance of the noise</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">std2</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">acc</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="o">/</span><span class="p">(</span><span class="n">acc</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">qpriors</span><span class="p">))]</span>

        <span class="c1"># Compute the covariance matrix</span>
        <span class="n">X</span> <span class="o">=</span> <span class="p">((</span><span class="n">acc_dq</span> <span class="o">-</span> <span class="n">acc</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">Dc</span> <span class="o">*</span> <span class="mf">1e-6</span><span class="p">))</span><span class="o">.</span><span class="n">T</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">X</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">Vstart</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">std2</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">X</span> </div>


<div class="viewcode-block" id="MCMC.acceptreject">
<a class="viewcode-back" href="../../src.html#src.MCMC.MCMC.acceptreject">[docs]</a>
    <span class="k">def</span> <span class="nf">acceptreject</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">q_new</span><span class="p">,</span> <span class="n">SSqprev</span><span class="p">,</span> <span class="n">std2</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Implement the Metropolis-Hastings acceptance/rejection criterion.</span>
<span class="sd">        </span>
<span class="sd">        This method determines whether to accept or reject a proposed parameter sample</span>
<span class="sd">        based on the Metropolis-Hastings algorithm. It first checks if the proposal</span>
<span class="sd">        falls within the prior bounds, then computes the acceptance probability based</span>
<span class="sd">        on the likelihood ratio, and finally makes a random decision.</span>
<span class="sd">        </span>
<span class="sd">        The acceptance probability is computed in log-space for numerical stability:</span>
<span class="sd">        log(α) = min(0, log(p(y|θ_new)/p(y|θ_old))) </span>
<span class="sd">               = min(0, -0.5 * (SSE_new - SSE_old) / σ²)</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            q_new (np.ndarray): Proposed parameter values with shape (n_params, 1).</span>
<span class="sd">            SSqprev (float): Sum of squared errors for the current/previous parameter values.</span>
<span class="sd">            std2 (float): Current estimate of the noise variance.</span>
<span class="sd">        </span>
<span class="sd">        Returns:</span>
<span class="sd">            tuple: A tuple containing:</span>
<span class="sd">                - accept (bool): True if the proposal is accepted, False otherwise</span>
<span class="sd">                - SSq (float): Sum of squared errors for the accepted state</span>
<span class="sd">                              (SSqnew if accepted, SSqprev if rejected)</span>
<span class="sd">        </span>
<span class="sd">        Algorithm Steps:</span>
<span class="sd">            1. Check if proposal is within prior bounds (uniform prior)</span>
<span class="sd">            2. If within bounds, evaluate model and compute likelihood ratio</span>
<span class="sd">            3. Compute log acceptance probability (clipped to [-∞, 0])</span>
<span class="sd">            4. Accept if log(α) &gt; log(U) where U ~ Uniform(0,1)</span>
<span class="sd">            5. Return acceptance decision and appropriate SSE value</span>
<span class="sd">        </span>
<span class="sd">        Mathematical Details:</span>
<span class="sd">            - Prior bounds check: lower_bound ≤ θ_new ≤ upper_bound</span>
<span class="sd">            - Log-likelihood ratio: Δ log L = -0.5 * (SSE_new - SSE_old) / σ²</span>
<span class="sd">            - Acceptance probability: α = min(1, exp(Δ log L))</span>
<span class="sd">            - Random acceptance: Accept if α &gt; U where U ~ Uniform(0,1)</span>
<span class="sd">        </span>
<span class="sd">        Note:</span>
<span class="sd">            - Uses np.clip to ensure log probability doesn&#39;t exceed 0</span>
<span class="sd">            - Proposals outside prior bounds are automatically rejected</span>
<span class="sd">            - The method handles both parameter bounds and likelihood evaluation</span>
<span class="sd">            - Random number generation uses np.random.rand() for uniform samples</span>
<span class="sd">        </span>
<span class="sd">        Example:</span>
<span class="sd">            &gt;&gt;&gt; q_proposal = np.array([[1.5]])</span>
<span class="sd">            &gt;&gt;&gt; accepted, sse = self.acceptreject(q_proposal, sse_current, variance_current)</span>
<span class="sd">            &gt;&gt;&gt; if accepted:</span>
<span class="sd">            ...     print(f&quot;Accepted proposal with SSE: {sse:.4f}&quot;)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Check if the proposal values are within the limits</span>
        <span class="n">condition1</span> <span class="o">=</span> <span class="p">(</span><span class="n">q_new</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">qstart_limits</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">])</span>
        <span class="n">condition2</span> <span class="o">=</span> <span class="p">(</span><span class="n">q_new</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">qstart_limits</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])</span>
        <span class="n">accept</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">condition1</span> <span class="o">&amp;</span> <span class="n">condition2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">accept</span><span class="p">:</span>
            <span class="c1"># Compute the sum of squares error of the new proposal</span>
            <span class="n">SSqnew</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">SSqcalc</span><span class="p">(</span><span class="n">q_new</span><span class="p">)</span>

            <span class="c1"># Compute the acceptance probability</span>
            <span class="n">accept_prob</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="mf">0.5</span> <span class="o">*</span> <span class="p">(</span><span class="n">SSqprev</span> <span class="o">-</span> <span class="n">SSqnew</span><span class="p">)</span> <span class="o">/</span> <span class="n">std2</span><span class="p">,</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>

            <span class="c1"># Check if the proposal is accepted </span>
            <span class="c1"># based on the acceptance probability and a random number</span>
            <span class="n">accept</span> <span class="o">=</span> <span class="n">accept_prob</span> <span class="o">&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">))[</span><span class="mi">0</span><span class="p">]</span>

        <span class="k">return</span> <span class="n">accept</span><span class="p">,</span> <span class="n">SSqnew</span> <span class="k">if</span> <span class="n">accept</span> <span class="k">else</span> <span class="n">SSqprev</span></div>


<div class="viewcode-block" id="MCMC.SSqcalc">
<a class="viewcode-back" href="../../src.html#src.MCMC.MCMC.SSqcalc">[docs]</a>
    <span class="k">def</span> <span class="nf">SSqcalc</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">q_new</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Calculate the sum of squared errors for proposed parameter values.</span>
<span class="sd">        </span>
<span class="sd">        This method evaluates the forward model with new parameter values and</span>
<span class="sd">        computes the sum of squared errors between model predictions and observed data.</span>
<span class="sd">        This quantity is used in the likelihood calculation for the Metropolis-Hastings</span>
<span class="sd">        acceptance criterion.</span>
<span class="sd">        </span>
<span class="sd">        The sum of squared errors (SSE) is a key component of the Gaussian likelihood:</span>
<span class="sd">        L(θ) ∝ exp(-SSE/(2σ²))</span>
<span class="sd">        where SSE = Σ(y_i - f(x_i, θ))²</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            q_new (np.ndarray): Proposed parameter values with shape (n_params,).</span>
<span class="sd">                              For this implementation, expects a 1D array where</span>
<span class="sd">                              the first element is the Dc parameter.</span>
<span class="sd">        </span>
<span class="sd">        Returns:</span>
<span class="sd">            np.ndarray: Sum of squared errors with shape (1, 1).</span>
<span class="sd">                       Returns as 2D array for consistency with matrix operations.</span>
<span class="sd">        </span>
<span class="sd">        Process:</span>
<span class="sd">            1. Update the model&#39;s Dc parameter with the proposed value</span>
<span class="sd">            2. Evaluate the forward model to get predictions</span>
<span class="sd">            3. Reshape predictions to match data format</span>
<span class="sd">            4. Compute squared differences between predictions and data</span>
<span class="sd">            5. Sum the squared errors and return as 2D array</span>
<span class="sd">        </span>
<span class="sd">        Mathematical Details:</span>
<span class="sd">            - SSE = Σᵢ (yᵢ - f(xᵢ, θ))²</span>
<span class="sd">            - Where yᵢ are observations, f(xᵢ, θ) are model predictions</span>
<span class="sd">            - Used in Gaussian log-likelihood: log L = -n/2 log(2πσ²) - SSE/(2σ²)</span>
<span class="sd">        </span>
<span class="sd">        Note:</span>
<span class="sd">            - Modifies self.model.Dc as a side effect</span>
<span class="sd">            - Assumes model.evaluate() returns predictions in appropriate format</span>
<span class="sd">            - Reshaping handles potential dimension mismatches between predictions and data</span>
<span class="sd">            - The keepdims parameter ensures output maintains 2D structure</span>
<span class="sd">        </span>
<span class="sd">        Example:</span>
<span class="sd">            &gt;&gt;&gt; q_test = np.array([1.2])</span>
<span class="sd">            &gt;&gt;&gt; sse = self.SSqcalc(q_test)</span>
<span class="sd">            &gt;&gt;&gt; print(f&quot;Sum of squared errors: {sse[0,0]:.4f}&quot;)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Update the Dc parameter of the model with the new proposal</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">Dc</span> <span class="o">=</span> <span class="n">q_new</span><span class="p">[</span><span class="mi">0</span><span class="p">,]</span>

        <span class="c1"># Evaluate the model&#39;s performance on the problem type and LSTM model</span>
        <span class="n">acc</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">evaluate_model</span><span class="p">()</span>
        
        <span class="c1"># Compute the sum of squares error between the model&#39;s accuracy and the data</span>
        <span class="n">SSq</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">acc</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">SSq</span></div>


<div class="viewcode-block" id="MCMC.sample">
<a class="viewcode-back" href="../../src.html#src.MCMC.MCMC.sample">[docs]</a>
    <span class="k">def</span> <span class="nf">sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">MAKE_ANIMATIONS</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Execute the main MCMC sampling algorithm with adaptive covariance updates.</span>
<span class="sd">        </span>
<span class="sd">        This method implements the complete adaptive Metropolis-Hastings algorithm,</span>
<span class="sd">        including initialization, proposal generation, acceptance/rejection decisions,</span>
<span class="sd">        covariance matrix adaptation, and noise variance updates. Optionally creates</span>
<span class="sd">        real-time animations of the sampling process.</span>
<span class="sd">        </span>
<span class="sd">        The algorithm follows these key steps:</span>
<span class="sd">        1. Initialize covariance matrix using finite differences</span>
<span class="sd">        2. For each iteration:</span>
<span class="sd">           - Generate proposal from multivariate normal distribution</span>
<span class="sd">           - Apply Metropolis-Hastings acceptance criterion</span>
<span class="sd">           - Update noise variance using Bayesian inference</span>
<span class="sd">           - Periodically adapt the proposal covariance matrix</span>
<span class="sd">        3. Return samples after burn-in period</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            MAKE_ANIMATIONS (bool): Whether to create and save real-time animations</span>
<span class="sd">                                  of the sampling evolution. Animations are saved as</span>
<span class="sd">                                  MP4 files with filenames including the true parameter value.</span>
<span class="sd">        </span>
<span class="sd">        Returns:</span>
<span class="sd">            np.ndarray: Array of accepted parameter samples after burn-in with shape</span>
<span class="sd">                       (n_params, n_samples_post_burnin). Only samples after the burn-in</span>
<span class="sd">                       period are returned for posterior analysis.</span>
<span class="sd">        </span>
<span class="sd">        Algorithm Details:</span>
<span class="sd">            - Proposal generation: θ_new ~ N(θ_current, V_current)</span>
<span class="sd">            - Acceptance rate tracking for diagnostic purposes</span>
<span class="sd">            - Adaptive covariance updates every &#39;adapt_interval&#39; samples</span>
<span class="sd">            - Hierarchical variance updates at each iteration</span>
<span class="sd">            - Burn-in removal for final sample return</span>
<span class="sd">        </span>
<span class="sd">        Animation Features (if MAKE_ANIMATIONS=True):</span>
<span class="sd">            - Real-time plot of parameter evolution</span>
<span class="sd">            - Automatic axis scaling based on sample range</span>
<span class="sd">            - Saved as MP4 with 30 fps using ffmpeg</span>
<span class="sd">            - Filename includes true parameter value for identification</span>
<span class="sd">        </span>
<span class="sd">        Diagnostic Output:</span>
<span class="sd">            - Sample index and acceptance status for each iteration</span>
<span class="sd">            - Generated sample values for monitoring</span>
<span class="sd">            - Final acceptance ratio for algorithm assessment</span>
<span class="sd">        </span>
<span class="sd">        Note:</span>
<span class="sd">            - Burn-in period is automatically set to nsamples/2</span>
<span class="sd">            - Failed covariance updates are caught and ignored</span>
<span class="sd">            - Animation requires matplotlib and ffmpeg</span>
<span class="sd">            - Memory is managed by closing figure after animation</span>
<span class="sd">        </span>
<span class="sd">        Performance Tips:</span>
<span class="sd">            - Set adapt_interval appropriately (typically 10-50)</span>
<span class="sd">            - Monitor acceptance ratio (target ~20-50%)</span>
<span class="sd">            - Use sufficient burn-in for convergence</span>
<span class="sd">            - Consider thinning for large sample sizes</span>
<span class="sd">        </span>
<span class="sd">        Example:</span>
<span class="sd">            &gt;&gt;&gt; # Run MCMC with animations</span>
<span class="sd">            &gt;&gt;&gt; samples = mcmc.sample(MAKE_ANIMATIONS=True)</span>
<span class="sd">            &gt;&gt;&gt; print(f&quot;Collected {samples.shape[1]} post-burn-in samples&quot;)</span>
<span class="sd">            &gt;&gt;&gt; print(f&quot;Posterior mean: {np.mean(samples, axis=1):.4f}&quot;)</span>
<span class="sd">            &gt;&gt;&gt; print(f&quot;Posterior std: {np.std(samples, axis=1):.4f}&quot;)</span>
<span class="sd">        </span>
<span class="sd">        Returns:</span>
<span class="sd">            The method returns samples from the posterior distribution that can be used for:</span>
<span class="sd">            - Parameter estimation (posterior mean, median)</span>
<span class="sd">            - Uncertainty quantification (credible intervals)</span>
<span class="sd">            - Model comparison (marginal likelihood estimation)</span>
<span class="sd">            - Diagnostic analysis (convergence assessment)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Compute initial covariance</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">compute_initial_covariance</span><span class="p">()</span>
        
        <span class="n">qparams</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="bp">self</span><span class="o">.</span><span class="n">qstart</span><span class="p">]]))</span> <span class="c1"># Array of sampled parameters</span>
        <span class="n">Vold</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Vstart</span><span class="p">)</span> <span class="c1"># Covariance matrix of previously sampled parameters</span>
        <span class="n">SSqprev</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">SSqcalc</span><span class="p">(</span><span class="n">qparams</span><span class="p">)</span> <span class="c1"># Squared error of previously sampled parameters</span>
        <span class="n">iaccept</span> <span class="o">=</span> <span class="mi">0</span> <span class="c1"># Counter for accepted samples</span>

        <span class="k">if</span> <span class="n">MAKE_ANIMATIONS</span><span class="p">:</span>
            <span class="c1"># Animation setup</span>
            <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
            <span class="n">line</span><span class="p">,</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">([],</span> <span class="p">[],</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
            <span class="c1"># Set title and labels</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;MCMC Sampling Evolution for dc = </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">dc_true</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> as True value&quot;</span><span class="p">)</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Sample Index&quot;</span><span class="p">)</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Sample Value&quot;</span><span class="p">)</span>

            <span class="k">def</span> <span class="nf">init</span><span class="p">():</span>
                <span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">nsamples</span><span class="p">)</span>  <span class="c1"># Set x-axis limits to the number of samples</span>
                <span class="c1"># Set y-axis limits to a range that covers the expected values of qparams</span>
                <span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">qparams</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">qparams</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> 
                <span class="k">return</span> <span class="n">line</span><span class="p">,</span>

            <span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="n">frame</span><span class="p">):</span>
                <span class="c1"># Update the line data to reflect the current state of qparams</span>
                <span class="c1"># x-axis: indices from 0 to frame, y-axis: qparams values up to current frame</span>
                <span class="n">line</span><span class="o">.</span><span class="n">set_data</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">frame</span><span class="p">),</span> <span class="n">qparams</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:</span><span class="n">frame</span><span class="p">])</span>
                <span class="k">return</span> <span class="n">line</span><span class="p">,</span>

            <span class="n">anim</span> <span class="o">=</span> <span class="n">FuncAnimation</span><span class="p">(</span><span class="n">fig</span><span class="p">,</span> <span class="n">update</span><span class="p">,</span> <span class="n">frames</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">nsamples</span><span class="p">,</span> <span class="n">init_func</span><span class="o">=</span><span class="n">init</span><span class="p">,</span> <span class="n">blit</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">isample</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nsamples</span><span class="p">):</span>
            <span class="c1"># Sample new parameters from a normal distribution </span>
            <span class="c1"># with mean being the last element of qparams</span>
            <span class="n">q_new</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">multivariate_normal</span><span class="p">(</span><span class="n">qparams</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span><span class="n">Vold</span><span class="p">),(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span> 

            <span class="c1"># Accept or reject the new sample based on the Metropolis-Hastings acceptance rule</span>
            <span class="n">accept</span><span class="p">,</span><span class="n">SSqnew</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">acceptreject</span><span class="p">(</span><span class="n">q_new</span><span class="p">,</span><span class="n">SSqprev</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">std2</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>

            <span class="c1"># Print some diagnostic information</span>
            <span class="nb">print</span><span class="p">(</span><span class="n">isample</span><span class="p">,</span><span class="n">accept</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Generated Sample ---- &quot;</span><span class="p">,</span> <span class="n">q_new</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
            <span class="c1"># print(&quot;Generated Sample ---- &quot;,np.asscalar(q_new))</span>

            <span class="k">if</span> <span class="n">accept</span><span class="p">:</span>
                <span class="c1"># If the new sample is accepted, </span>
                <span class="c1"># add it to the list of sampled parameters</span>
                <span class="n">qparams</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">qparams</span><span class="p">,</span><span class="n">q_new</span><span class="p">),</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
                <span class="n">SSqprev</span> <span class="o">=</span> <span class="n">SSqnew</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
                <span class="n">iaccept</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># If the new sample is rejected, </span>
                <span class="c1"># add the previous sample to the list of sampled parameters</span>
                <span class="n">q_new</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">qparams</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">],(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
                <span class="n">qparams</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">qparams</span><span class="p">,</span><span class="n">q_new</span><span class="p">),</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">update_standard_deviation</span><span class="p">(</span><span class="n">SSqprev</span><span class="p">)</span>
            <span class="c1"># Update standard deviation</span>

            <span class="c1"># Update the covariance matrix if it is time to adapt it</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">isample</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">adapt_interval</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="n">Vold</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">update_covariance_matrix</span><span class="p">(</span><span class="n">qparams</span><span class="p">)</span>
                <span class="k">except</span><span class="p">:</span>
                    <span class="k">pass</span>

        <span class="c1"># Print acceptance ratio</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;acceptance ratio:&quot;</span><span class="p">,</span><span class="n">iaccept</span><span class="o">/</span><span class="bp">self</span><span class="o">.</span><span class="n">nsamples</span><span class="p">)</span>

       <span class="c1"># Trim the estimate of the standard deviation to exclude burn-in samples  </span>
        <span class="bp">self</span><span class="o">.</span><span class="n">std2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">std2</span><span class="p">)[</span><span class="bp">self</span><span class="o">.</span><span class="n">nburn</span><span class="p">:]</span> 

        <span class="k">if</span> <span class="n">MAKE_ANIMATIONS</span><span class="p">:</span>
            <span class="c1"># Save the animation with the extracted dc_value in the filename</span>
            <span class="n">filename</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;mcmc_animation_dc_</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">dc_true</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">.mp4&#39;</span>  
            <span class="n">anim</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="n">fps</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">writer</span><span class="o">=</span><span class="s1">&#39;ffmpeg&#39;</span><span class="p">)</span>

            <span class="c1"># Close the figure to free up memory</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">(</span><span class="n">fig</span><span class="p">)</span>

        <span class="c1"># Return accepted samples</span>
        <span class="k">return</span> <span class="n">qparams</span><span class="p">[:,</span><span class="bp">self</span><span class="o">.</span><span class="n">nburn</span><span class="p">:]</span></div>
</div>

</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2025, Saumik Dana.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>